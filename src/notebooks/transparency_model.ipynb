{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from data_preparation.Transparency_data_preparation import (\n",
    "    create_transparency_pipeline,\n",
    "    prepare_am_transparency_data,\n",
    "    prepare_pm_transparency_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb(X_train, y_train, X_dev, y_dev):\n",
    "    print(\"Evaluating XGBoost Regressor...\")\n",
    "\n",
    "    # Define the hyperparameter grid search to try combinations of these hyperparameters.\n",
    "    param_grid = {\n",
    "        'algo__n_estimators': [1000],\n",
    "        'algo__max_depth': [2, 3, 4],\n",
    "        'algo__learning_rate': [0.01, 0.05, 0.1], # smaller learning rate is possibly better as training consisitency increasees.\n",
    "        'algo__subsample': [0.8, 1.0],\n",
    "    }\n",
    "\n",
    "    # This here uses the pipeline to handle missing values, scaling, encoding, etc for teh dataset.\n",
    "    pipeline = create_transparency_pipeline()\n",
    "\n",
    "    # This combines the preprocessing and XGBoost model into one clean pipeline.\n",
    "    pipeline_with_algo = Pipeline(steps=[\n",
    "        ('preprocessor', pipeline),\n",
    "        ('algo', XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline_with_algo, param_grid,\n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        scoring='neg_mean_squared_error',  \n",
    "        verbose=1  # Show progress in terminal\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # This shows us our best model based on cross-validation RÂ² score.\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    # ðŸ“Š FEATURE IMPORTANCE SECTION\n",
    "    try:\n",
    "        model = best_estimator.named_steps[\"algo\"]\n",
    "        preprocessor = best_estimator.named_steps[\"preprocessor\"]\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        importances = model.feature_importances_\n",
    "\n",
    "        feature_df = pd.DataFrame({\n",
    "            \"Feature\": feature_names,\n",
    "            \"Importance\": importances\n",
    "        }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        print(feature_df.head(10))\n",
    "    except Exception as e:\n",
    "        print(\"Could not extract feature importances:\", e)\n",
    "\n",
    "    # We are making predicitons on the dev set here\n",
    "    y_pred = best_estimator.predict(X_dev)\n",
    "\n",
    "    # Here we are calculating the following values\n",
    "    # Calculate evaluation metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_dev, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_dev, y_pred)\n",
    "    r2 = r2_score(y_dev, y_pred)\n",
    "\n",
    "    # Shows you the best performance from the training phase and the hyperparameters that gave it.\n",
    "    print(\"Grid searching is done!\")\n",
    "    print(\"Best score (neg MSE):\", grid_search.best_score_)\n",
    "    print(\"Best hyperparameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    return best_estimator, rmse, mape, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(y_true, y_pred, label, target):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mean_target = np.mean(y_true)\n",
    "    print(f\"\\nðŸ“Š {label} Set Performance for {target}:\")\n",
    "    print(f\"Mean of y_{label.lower()}: {mean_target:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.4f}\")\n",
    "    print(f\"RÂ²: {r2:.4f}\")\n",
    "    return rmse, mape, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Evaluating model for: AM Transparency\n",
      "Evaluating XGBoost Regressor...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                     Feature  Importance\n",
      "3              num__Dec Rain    0.142629\n",
      "6    num__Spring_Temp x Rain    0.132109\n",
      "18        cat__Season_Spring    0.121022\n",
      "0       num__Spring Temp (F)    0.112140\n",
      "1          num__Max air temp    0.096366\n",
      "2          num__Min air temp    0.089482\n",
      "13     num__Dec Rain (Lag 1)    0.071137\n",
      "4           num__Calmar Rain    0.054574\n",
      "9      num__Dec Rain (Lag 3)    0.041428\n",
      "7   num__Max Air Temp x Rain    0.039811\n",
      "Grid searching is done!\n",
      "Best score (neg MSE): -45.688628658055926\n",
      "Best hyperparameters:\n",
      "{'algo__learning_rate': 0.1, 'algo__max_depth': 4, 'algo__n_estimators': 1000, 'algo__subsample': 1.0}\n",
      "âœ… Data Split Shapes:\n",
      "  X_train: (18632, 18)\n",
      "  X_dev: (2329, 18)\n",
      "  X_test: (2329, 18)\n",
      "  y_train: (18632,)\n",
      "  y_dev: (2329,)\n",
      "  y_test: (2329,)\n",
      "\n",
      "ðŸ“Š Train Set Performance for AM Transparency:\n",
      "Mean of y_train: 20.9645\n",
      "RMSE: 2.3548\n",
      "MAPE: 0.1258\n",
      "RÂ²: 0.9990\n",
      "\n",
      "ðŸ“Š Dev Set Performance for AM Transparency:\n",
      "Mean of y_dev: 23.0279\n",
      "RMSE: 4.3290\n",
      "MAPE: 0.1466\n",
      "RÂ²: 0.9973\n",
      "\n",
      "ðŸ“Š Test Set Performance for AM Transparency:\n",
      "Mean of y_test: 21.5661\n",
      "RMSE: 4.2677\n",
      "MAPE: 0.1566\n",
      "RÂ²: 0.9966\n",
      "âœ… Model saved as: ../models/am_transparency_model.joblib\n",
      "\n",
      "ðŸš€ Evaluating model for: PM Transparency\n",
      "Evaluating XGBoost Regressor...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                     Feature  Importance\n",
      "7   num__Max Air Temp x Rain    0.214025\n",
      "6    num__Spring_Temp x Rain    0.203252\n",
      "3              num__Dec Rain    0.126455\n",
      "0       num__Spring Temp (F)    0.083331\n",
      "9      num__Dec Rain (Lag 3)    0.082138\n",
      "18        cat__Season_Spring    0.051140\n",
      "4           num__Calmar Rain    0.031958\n",
      "11     num__Dec Rain (Lag 2)    0.028255\n",
      "15   num__Dec Rain 7-day avg    0.023529\n",
      "2          num__Min air temp    0.022243\n",
      "Grid searching is done!\n",
      "Best score (neg MSE): -61.076605441413406\n",
      "Best hyperparameters:\n",
      "{'algo__learning_rate': 0.1, 'algo__max_depth': 4, 'algo__n_estimators': 1000, 'algo__subsample': 0.8}\n",
      "âœ… Data Split Shapes:\n",
      "  X_train: (18632, 18)\n",
      "  X_dev: (2329, 18)\n",
      "  X_test: (2329, 18)\n",
      "  y_train: (18632,)\n",
      "  y_dev: (2329,)\n",
      "  y_test: (2329,)\n",
      "\n",
      "ðŸ“Š Train Set Performance for PM Transparency:\n",
      "Mean of y_train: 19.0167\n",
      "RMSE: 1.7767\n",
      "MAPE: 0.1113\n",
      "RÂ²: 0.9992\n",
      "\n",
      "ðŸ“Š Dev Set Performance for PM Transparency:\n",
      "Mean of y_dev: 20.3451\n",
      "RMSE: 7.6356\n",
      "MAPE: 0.1426\n",
      "RÂ²: 0.9875\n",
      "\n",
      "ðŸ“Š Test Set Performance for PM Transparency:\n",
      "Mean of y_test: 18.1580\n",
      "RMSE: 3.7028\n",
      "MAPE: 0.1388\n",
      "RÂ²: 0.9952\n",
      "âœ… Model saved as: ../models/pm_transparency_model.joblib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    for target in [\"AM Transparency\", \"PM Transparency\"]:\n",
    "        print(f\"\\nðŸš€ Evaluating model for: {target}\")\n",
    "\n",
    "        if target == \"AM Transparency\":\n",
    "            X_train, X_dev, X_test, y_train, y_dev, y_test = prepare_am_transparency_data()\n",
    "            model_filename = \"../models/am_transparency_model.joblib\"\n",
    "        else:\n",
    "            X_train, X_dev, X_test, y_train, y_dev, y_test = prepare_pm_transparency_data()\n",
    "            model_filename = \"../models/pm_transparency_model.joblib\"\n",
    "\n",
    "        best_model, dev_rmse, dev_mape, dev_r2 = evaluate_xgb(X_train, y_train, X_dev, y_dev)\n",
    "\n",
    "        print(\"âœ… Data Split Shapes:\")\n",
    "        print(\"  X_train:\", X_train.shape)\n",
    "        print(\"  X_dev:\", X_dev.shape)\n",
    "        print(\"  X_test:\", X_test.shape)\n",
    "        print(\"  y_train:\", y_train.shape)\n",
    "        print(\"  y_dev:\", y_dev.shape)\n",
    "        print(\"  y_test:\", y_test.shape)\n",
    "\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_dev_pred = best_model.predict(X_dev)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "        evaluate_metrics(y_train, y_train_pred, \"Train\", target)\n",
    "        evaluate_metrics(y_dev, y_dev_pred, \"Dev\", target)\n",
    "        evaluate_metrics(y_test, y_test_pred, \"Test\", target)\n",
    "\n",
    "        dump(best_model, model_filename)\n",
    "        print(f\"âœ… Model saved as: {model_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
