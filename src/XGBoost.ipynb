{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost\n",
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_preparation import create_fish_pipeline, prepare_fish_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb(X_train, y_train, X_dev, y_dev):\n",
    "    print(\"Evaluating XGBoost Regressor...\")\n",
    "\n",
    "    # Define the hyperparameter grid search to try combinations of these hyperparameters.\n",
    "    param_grid = {\n",
    "        'algo__n_estimators': [50, 100],\n",
    "        'algo__max_depth': [3, 5],\n",
    "        'algo__learning_rate': [0.05, 0.1],\n",
    "        'algo__subsample': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # This here uses the pipeline to handle missing values, scaling, encoding, etc for teh dataset.\n",
    "    pipeline = create_fish_pipeline()\n",
    "\n",
    "    # This combines the preprocessing and XGBoost model into one clean pipeline.\n",
    "    pipeline_with_algo = Pipeline(steps=[\n",
    "        ('preprocessor', pipeline),\n",
    "        ('algo', XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline_with_algo, param_grid,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='r2',  # Use R¬≤ as the evaluation metric\n",
    "        verbose=1  # Show progress in terminal\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # This shows us our best model based on cross-validation R¬≤ score.\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    # We are making predicitons on the dev set here\n",
    "    y_pred = best_estimator.predict(X_dev)\n",
    "\n",
    "    # Here we are calculating the following values\n",
    "    mse = mean_squared_error(y_dev, y_pred)\n",
    "    mae = mean_absolute_error(y_dev, y_pred)\n",
    "    r2 = r2_score(y_dev, y_pred)\n",
    "\n",
    "    # Shows you the best performance from the training phase and the hyperparameters that gave it.\n",
    "    print(\"Grid searching is done!\")\n",
    "    print(\"Best score (neg MSE):\", grid_search.best_score_)\n",
    "    print(\"Best hyperparameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    return best_estimator, mse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare fish data (split into train/dev/test)\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = prepare_fish_data(ratios=((1/10), (1/10)))\n",
    "\n",
    "# Step 2: Run hyperparameter tuning on train/dev sets\n",
    "best_model, dev_mse, dev_mae, dev_r2 = evaluate_xgb(X_train, y_train, X_dev, y_dev)\n",
    "\n",
    "print(\"\\n----- Dev Set Performance -----\")\n",
    "print(\"Dev MSE:\", dev_mse)\n",
    "print(\"Dev MAE:\", dev_mae)\n",
    "print(\"Dev R¬≤:\", dev_r2)\n",
    "\n",
    "# Step 3: Evaluate best model on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n----- Test Set Performance -----\")\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test MAE:\", test_mae)\n",
    "print(\"Test R¬≤:\", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Observations from the Data Stats\n",
    "\n",
    "### üìâ Missing Values\n",
    "- Columns like **\"AM Transparency\"**, **\"PM Transparency\"**, and **\"Spring Temp\"** have missing values (their count is less than the total 28,918 rows).\n",
    "- ‚úÖ Your pipeline handles this using `SimpleImputer` and `KNNImputer`.\n",
    "\n",
    "### üìä Wide Value Ranges\n",
    "- **Transparency** values go above **1200**, so scaling is needed ‚Äî ‚úÖ you're using `StandardScaler`.\n",
    "- **Fish counts** range from **220 to 51,827**, creating large variance ‚Äî yet your model handled it well (**Test R¬≤ ~0.81**).\n",
    "\n",
    "### üéØ Survival Rate\n",
    "- \"Fish survival rate\" ranges from **~68% to 100%**\n",
    "- Mean ‚âà **99.97%** ‚Üí Highly **imbalanced**, as most fish survive.\n",
    "- ‚úÖ Your model's low **MAE (‚âà 0.0098)** shows it's accurately predicting survival rates even in this tight range.\n",
    "\n",
    "### üìù Other Notes\n",
    "- **Rain values** include 0 ‚Äî makes sense seasonally.\n",
    "- **Temperature and rainfall** columns are continuous ‚Äî great for regression models.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why Your Pipeline Is Working\n",
    "\n",
    "Your preprocessing pipeline and model work well because:\n",
    "\n",
    "| Problem                              | Solution in Pipeline                   |\n",
    "|--------------------------------------|----------------------------------------|\n",
    "| Missing transparency/temp values     | `KNNImputer`, `SimpleImputer`          |\n",
    "| Large numeric value ranges           | `StandardScaler`                       |\n",
    "| Categorical feeding/location columns | `OneHotEncoder`                        |\n",
    "| Special handling for `\"Morts\"`       | Filled with `0` using `SimpleImputer` ‚úÖ |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why the Model Performed Well\n",
    "\n",
    "| Metric     | Result     | Interpretation                              |\n",
    "|------------|------------|----------------------------------------------|\n",
    "| Dev R¬≤     | 0.96       | Extremely good fit to known (dev) data       |\n",
    "| Test R¬≤    | 0.81       | Strong generalization to unseen (test) data  |\n",
    "| MAE        | ~0.0098    | Average error is <1% of survival rate ‚Äî ‚úÖ very precise |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the preprocessor from the trained pipeline\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Transform the training data\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "\n",
    "# If it's a sparse matrix, convert it to dense\n",
    "if hasattr(X_train_transformed, \"toarray\"):\n",
    "    X_train_transformed = X_train_transformed.toarray()\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_train_df = pd.DataFrame(X_train_transformed)\n",
    "\n",
    "# Optional: Add target column\n",
    "X_train_df[\"Survival Rate\"] = y_train.reset_index(drop=True)\n",
    "\n",
    "# Preview\n",
    "print(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.to_excel(\"../Data/Prepared/preprocessed_train_data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
