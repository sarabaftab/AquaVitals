{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/sarabaftab/Desktop/Pi515-AI/.venv/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /Users/sarabaftab/Desktop/Pi515-AI/.venv/lib/python3.10/site-packages (from xgboost) (2.2.4)\n",
      "Requirement already satisfied: scipy in /Users/sarabaftab/Desktop/Pi515-AI/.venv/lib/python3.10/site-packages (from xgboost) (1.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in /Users/sarabaftab/Desktop/Pi515-AI/.venv/lib/python3.10/site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost\n",
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_preparation import create_fish_pipeline, prepare_fish_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgb(X_train, y_train, X_dev, y_dev):\n",
    "    print(\"Evaluating XGBoost Regressor...\")\n",
    "\n",
    "    # Define the hyperparameter grid search to try combinations of these hyperparameters.\n",
    "    param_grid = {\n",
    "        'algo__n_estimators': [50, 100],\n",
    "        'algo__max_depth': [3, 5],\n",
    "        'algo__learning_rate': [0.05, 0.1],\n",
    "        'algo__subsample': [0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    # This here uses the pipeline to handle missing values, scaling, encoding, etc for teh dataset.\n",
    "    pipeline = create_fish_pipeline()\n",
    "\n",
    "    # This combines the preprocessing and XGBoost model into one clean pipeline.\n",
    "    pipeline_with_algo = Pipeline(steps=[\n",
    "        ('preprocessor', pipeline),\n",
    "        ('algo', XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline_with_algo, param_grid,\n",
    "        cv=3,  # 3-fold cross-validation\n",
    "        scoring='r2',  # Use R¬≤ as the evaluation metric\n",
    "        verbose=1  # Show progress in terminal\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # This shows us our best model based on cross-validation R¬≤ score.\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "\n",
    "    # We are making predicitons on the dev set here\n",
    "    y_pred = best_estimator.predict(X_dev)\n",
    "\n",
    "    # Here we are calculating the following values\n",
    "    mse = mean_squared_error(y_dev, y_pred)\n",
    "    mae = mean_absolute_error(y_dev, y_pred)\n",
    "    r2 = r2_score(y_dev, y_pred)\n",
    "\n",
    "    # Shows you the best performance from the training phase and the hyperparameters that gave it.\n",
    "    print(\"Grid searching is done!\")\n",
    "    print(\"Best score (neg MSE):\", grid_search.best_score_)\n",
    "    print(\"Best hyperparameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    return best_estimator, mse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating XGBoost Regressor...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Grid searching is done!\n",
      "Best score (neg MSE): 0.7343398167270424\n",
      "Best hyperparameters:\n",
      "{'algo__learning_rate': 0.1, 'algo__max_depth': 3, 'algo__n_estimators': 100, 'algo__subsample': 1.0}\n",
      "\n",
      "----- Dev Set Performance -----\n",
      "Dev MSE: 0.0006988098230355483\n",
      "Dev MAE: 0.0061427891355794765\n",
      "Dev R¬≤: 0.9617233611821583\n",
      "\n",
      "----- Test Set Performance -----\n",
      "Test MSE: 0.036535925060766236\n",
      "Test MAE: 0.009838734049708876\n",
      "Test R¬≤: 0.8160805460065046\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare fish data (split into train/dev/test)\n",
    "X_train, X_dev, X_test, y_train, y_dev, y_test = prepare_fish_data(ratios=((1/10), (1/10)))\n",
    "\n",
    "# Step 2: Run hyperparameter tuning on train/dev sets\n",
    "best_model, dev_mse, dev_mae, dev_r2 = evaluate_xgb(X_train, y_train, X_dev, y_dev)\n",
    "\n",
    "print(\"\\n----- Dev Set Performance -----\")\n",
    "print(\"Dev MSE:\", dev_mse)\n",
    "print(\"Dev MAE:\", dev_mae)\n",
    "print(\"Dev R¬≤:\", dev_r2)\n",
    "\n",
    "# Step 3: Evaluate best model on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n----- Test Set Performance -----\")\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Test MAE:\", test_mae)\n",
    "print(\"Test R¬≤:\", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Observations from the Data Stats\n",
    "\n",
    "### üìâ Missing Values\n",
    "- Columns like **\"AM Transparency\"**, **\"PM Transparency\"**, and **\"Spring Temp\"** have missing values (their count is less than the total 28,918 rows).\n",
    "- ‚úÖ Your pipeline handles this using `SimpleImputer` and `KNNImputer`.\n",
    "\n",
    "### üìä Wide Value Ranges\n",
    "- **Transparency** values go above **1200**, so scaling is needed ‚Äî ‚úÖ you're using `StandardScaler`.\n",
    "- **Fish counts** range from **220 to 51,827**, creating large variance ‚Äî yet your model handled it well (**Test R¬≤ ~0.81**).\n",
    "\n",
    "### üéØ Survival Rate\n",
    "- \"Fish survival rate\" ranges from **~68% to 100%**\n",
    "- Mean ‚âà **99.97%** ‚Üí Highly **imbalanced**, as most fish survive.\n",
    "- ‚úÖ Your model's low **MAE (‚âà 0.0098)** shows it's accurately predicting survival rates even in this tight range.\n",
    "\n",
    "### üìù Other Notes\n",
    "- **Rain values** include 0 ‚Äî makes sense seasonally.\n",
    "- **Temperature and rainfall** columns are continuous ‚Äî great for regression models.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why Your Pipeline Is Working\n",
    "\n",
    "Your preprocessing pipeline and model work well because:\n",
    "\n",
    "| Problem                              | Solution in Pipeline                   |\n",
    "|--------------------------------------|----------------------------------------|\n",
    "| Missing transparency/temp values     | `KNNImputer`, `SimpleImputer`          |\n",
    "| Large numeric value ranges           | `StandardScaler`                       |\n",
    "| Categorical feeding/location columns | `OneHotEncoder`                        |\n",
    "| Special handling for `\"Morts\"`       | Filled with `0` using `SimpleImputer` ‚úÖ |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Why the Model Performed Well\n",
    "\n",
    "| Metric     | Result     | Interpretation                              |\n",
    "|------------|------------|----------------------------------------------|\n",
    "| Dev R¬≤     | 0.96       | Extremely good fit to known (dev) data       |\n",
    "| Test R¬≤    | 0.81       | Strong generalization to unseen (test) data  |\n",
    "| MAE        | ~0.0098    | Average error is <1% of survival rate ‚Äî ‚úÖ very precise |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "0     -0.050199 -0.078393 -1.151880 -1.067648 -0.311425 -0.317489 -0.340997   \n",
      "1      0.044104  1.402440  0.841232  0.551391 -0.342785 -0.317489 -0.352084   \n",
      "2     -0.050199 -0.882582 -0.198653 -0.115272 -0.342785 -0.348926 -0.521603   \n",
      "3     -0.003048 -0.378859  0.104647 -0.258129 -0.342785 -0.348926 -1.486657   \n",
      "4     -0.050199  1.140310  1.144531  1.456148  0.942978  0.782803 -0.345348   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "23131 -0.050199  1.035716  1.144531  0.503772 -0.342785 -0.348926 -0.192387   \n",
      "23132 -0.050199  0.044681  1.231188  1.122816 -0.342785 -0.348926 -0.152253   \n",
      "23133  0.044104 -1.347008 -1.975122 -1.877168  0.221696  0.185502 -0.275744   \n",
      "23134 -0.050199 -0.937113 -1.325194 -1.591455  0.221696  0.279812 -0.432914   \n",
      "23135 -0.050199  0.035668  0.537932 -0.067653 -0.311425 -0.254615 -0.295390   \n",
      "\n",
      "              7          8          9  ...  100  101  102  103  104  105  106  \\\n",
      "0     -0.340742   9.738994   9.738994  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "1     -0.352677  88.186891  54.741739  ...  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
      "2     -0.521450   9.738994   9.738994  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "3     -1.487471   9.738994   9.738994  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "4     -0.345095  20.633123  18.749031  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "...         ...        ...        ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "23131 -0.192048   7.930000   7.990833  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "23132 -0.151890  14.705833  33.751667  ...  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
      "23133 -0.276294   9.738994   9.738994  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "23134 -0.432710   9.738994   9.738994  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "23135 -0.295109   9.738994   9.738994  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
      "\n",
      "       107  108  Survival Rate  \n",
      "0      0.0  1.0     100.000000  \n",
      "1      0.0  0.0      99.932470  \n",
      "2      0.0  1.0     100.000000  \n",
      "3      0.0  1.0      99.625000  \n",
      "4      0.0  1.0     100.000000  \n",
      "...    ...  ...            ...  \n",
      "23131  0.0  1.0     100.000000  \n",
      "23132  0.0  0.0     100.000000  \n",
      "23133  0.0  1.0      99.936367  \n",
      "23134  0.0  1.0     100.000000  \n",
      "23135  0.0  1.0     100.000000  \n",
      "\n",
      "[23136 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the preprocessor from the trained pipeline\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "\n",
    "# Transform the training data\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "\n",
    "# If it's a sparse matrix, convert it to dense\n",
    "if hasattr(X_train_transformed, \"toarray\"):\n",
    "    X_train_transformed = X_train_transformed.toarray()\n",
    "\n",
    "# Convert to DataFrame\n",
    "X_train_df = pd.DataFrame(X_train_transformed)\n",
    "\n",
    "# Optional: Add target column\n",
    "X_train_df[\"Survival Rate\"] = y_train.reset_index(drop=True)\n",
    "\n",
    "# Preview\n",
    "print(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.to_excel(\"../Data/Prepared/preprocessed_train_data.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
